# 🐸 RibbID

**RibbID** is a bioacoustic machine learning project designed to identify multiple species of frogs and toads (order *Anura*) in field audio recordings from Catalonia (northern Spain). Leveraging convolutional neural networks on spectrogram inputs and classical baselines, the model can detect the presence of one or more of **nine target species** within a single recording.

https://huggingface.co/spaces/Calotriton/RibbID

---

## 📑 Table of Contents

1. [🧠 Project Overview](#-project-overview)
2. [🐸 Target Species](#-target-species)
3. [🗂️ Repository Structure](#️-repository-structure)
4. [⚙️ Installation](#️-installation)
5. [📁 Data Organization](#-data-organization)
6. [🚀 Usage](#-usage)
7. [🤝 Development & Contributing](#-development--contributing)
8. [📄 License](#-license)

---

## 🧠 Project Overview

The goal of **RibbID** is to provide researchers and conservationists with a tool to automatically detect and identify multiple frog species from a single audio recording. By focusing exclusively on frogs native to Catalonia, the model is specialized for local biodiversity monitoring and can be integrated into desktop or mobile applications for real‑time or batch inference.

The project is totally usable and can be found deployed in: https://huggingface.co/spaces/Calotriton/RibbID

### 🔑 Key Features

- **Multi‑label classification**: Detect more than one species in the same clip.
- **Local species focus**: Optimized for nine common Catalan frog species.
- **Flexible deployment**: Exportable to TensorFlow Lite, ONNX, or PyTorch Mobile.
- **Reproducible pipeline**: Clear directory structure, documented notebooks, and modular source code.

---

## 🐸 Target Species

The model is trained to identify the following species of *Anura* found in Catalonia, northern Spain:

1. **Alytes obstetricans** *(Common midwife toad)*
2. **Bufo spinosus** *(Spiny toad)*
3. **Epidalea calamita** *(Natterjack toad)*
4. **Hyla meridionalis** *(Mediterranean tree frog)*
5. **Pelobates cultripes** *(Western spadefoot)*
6. **Pelodytes punctatus** *(Common parsley frog)*
7. **Pelophylax spp.** *(Green frogs complex)*
8. **Rana temporaria** *(Common frog)*

---

## 🗂️ Repository Structure

```plaintext
RibbID/
├── data/
│   ├── raw/             # Original field recordings (.wav/.flac)
│   ├── processed/       # Extracted features (MFCC, spectrogram arrays)
│   └── cleaned/         # Final cleaned metadata and filtered recordings
│
├── notebooks/           # Numbered Jupyter Notebooks for EDA, preprocessing, training
│   ├── RibbID.ipynb
│
├── models/              # Saved model checkpoints and exported artifacts
│   ├── CNN              # CNN model, including the label encoder, detection thresholds and calibrator
│   ├── SVM              # SVM model, including the scaler and the mfcc spectrograms
│
├── environment.yml      # Conda environment specification
├── requirements.txt     # Pip requirements (if used)
├── .gitignore           # Ignore patterns for Git
└── README.md            # Project overview and instructions
```

---

## ⚙️ Installation

### 1. Clone the repository

```bash
git clone https://github.com/Calotriton/RibbID.git
cd RibbID
```

### 2. Set up the Conda environment (recommended)

```bash
conda env create -f environment.yml
conda activate RibbID
```

### 3. (Optional) Install via pip

```bash
pip install -r requirements.txt
```

---

## 📁 Data Organization

Place your raw audio files in the following structure:

```
data/
├── raw/           # Original audio files (.wav, .flac)
├── processed/     # Preprocessed spectrogram arrays or features
└── cleaned/       # Cleaned metadata CSVs, trimmed subsets
```

Metadata should be stored as `metadata.csv` with columns:

- `filename`, `species`, `date`, `time`, `location`, `notes`

---

## 🚀 Usage

### 1. Launch the notebooks

For exploration and prototyping:

```bash
jupyter notebook notebooks/01_exploration.ipynb
```

### 2. Train the model

```bash
python src/train.py   --data-dir data/processed   --output-dir models/   --epochs 50   --batch-size 32
```

### 3. Run inference on new recordings

```python
from src.inference import predict_multilabel

results = predict_multilabel("data/raw/your_recording.wav")
print(results)  # Example output: {"Alytes obstetricans": 0.81, "Hyla meridionalis": 0.64}
```

---

## 🤝 Development & Contributing

We welcome all contributions! To contribute:

1. **Fork** the repository  
2. **Create a new branch**:  
   ```bash
   git checkout -b feature/my-feature
   ```
3. **Make changes**, then commit and push  
4. **Open a Pull Request** and explain your changes

Please follow PEP8 and add meaningful docstrings. Tests and reproducible examples are highly appreciated!

---

## 📄 License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

### 💚 Citation

If you use RibbID for research or conservation purposes, cite the present repository.

---
